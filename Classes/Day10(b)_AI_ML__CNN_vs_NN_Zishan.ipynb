{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krit-Barnwal/Summer-Ai-Ml/blob/main/ORL_ACCURACY_COMPARISION_Krit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgY5DeQPiIM5"
      },
      "outputs": [],
      "source": [
        "# Perform traing and testing accurary comparision on ORL Benchmark dataset with following models\n",
        "#     SVM\n",
        "#     AI INIT\n",
        "#     CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.image as mimg\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm,model_selection,metrics\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "j8Sp36eHlIUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting the google drive\n",
        "\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6wfQ_ZiiXJl",
        "outputId": "84e15420-a2b8-4f67-f421-1d5260552960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip '/gdrive/MyDrive/Colab Notebooks/orl_face.zip' -d '/gdrive/MyDrive/Colab Notebooks/orl_face'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzI6icgnnSIS",
        "outputId": "d70d148a-e16a-4ffc-8685-af02b2031dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /gdrive/MyDrive/Colab Notebooks/orl_face.zip, /gdrive/MyDrive/Colab Notebooks/orl_face.zip.zip or /gdrive/MyDrive/Colab Notebooks/orl_face.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOJ45l85xYLW",
        "outputId": "b6a99f7b-b43d-4737-e240-75b5b6089fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access any single image\n",
        "\n",
        "usr_name = 40\n",
        "samp_no = 6\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Colab_Notebooks/orl_face/orl_face/u%d/%d.png\"%(40,1)\n",
        "\n",
        "# read the image\n",
        "im = mimg.imread(dataset_path)\n",
        "\n",
        "print(type(im))\n",
        "print(im.shape)\n",
        "\n",
        "# display the image\n",
        "plt.imshow(im,cmap='gray')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "lO3GtRjOjQGU",
        "outputId": "f33bf068-d308-4c77-e0c1-21d19f2a2f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(112, 92)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 91.5, 111.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the 2D-data of image into 1-D features\n",
        "feat = im.reshape(1,-1)# shift all the values of the image\n",
        "#into the columns in one single row\n",
        "print(im.shape)\n",
        "print(feat.shape)\n",
        "print(\"range:\",im.min(),'-',im.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo5rSgPrjwdU",
        "outputId": "a9dd2556-6b80-46f4-ee73-2897738c7409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(112, 92)\n",
            "(1, 10304)\n",
            "range: 0.019607844 - 0.8156863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logic to access all the samples of all\n",
        "# the users\n",
        "num_users = 40\n",
        "num_samples = 10\n",
        "tot_samples = num_users*num_samples\n",
        "data = np.zeros((tot_samples,im.shape[0]*im.shape[1]))\n",
        "label = np.zeros((tot_samples))\n",
        "images = np.zeros((tot_samples,im.shape[0],im.shape[1]))\n",
        "indx=-1\n",
        "for i in range(1,num_users+1,1): # to traverse users\n",
        "  for j in range(1,num_samples+1,1): # to traverse samples\n",
        "    indx = indx+1\n",
        "    # access any single image\n",
        "    usr_name = i\n",
        "    samp_no = j\n",
        "\n",
        "    path = \"/content/drive/MyDrive/Colab_Notebooks/orl_face/orl_face/u%d/%d.png\"%(usr_name,samp_no)\n",
        "\n",
        "    # read the image\n",
        "    im = mimg.imread(path)\n",
        "    feat = im.reshape(1,-1)\n",
        "    data[indx,:]=feat\n",
        "    label[indx]=i\n",
        "    images[indx,:,:]=im\n",
        "    print(\"user num \",i,'samp no',j,'processed...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-wNitPqj8OB",
        "outputId": "386b5907-4cff-487c-de82-220e67910310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user num  1 samp no 1 processed...\n",
            "user num  1 samp no 2 processed...\n",
            "user num  1 samp no 3 processed...\n",
            "user num  1 samp no 4 processed...\n",
            "user num  1 samp no 5 processed...\n",
            "user num  1 samp no 6 processed...\n",
            "user num  1 samp no 7 processed...\n",
            "user num  1 samp no 8 processed...\n",
            "user num  1 samp no 9 processed...\n",
            "user num  1 samp no 10 processed...\n",
            "user num  2 samp no 1 processed...\n",
            "user num  2 samp no 2 processed...\n",
            "user num  2 samp no 3 processed...\n",
            "user num  2 samp no 4 processed...\n",
            "user num  2 samp no 5 processed...\n",
            "user num  2 samp no 6 processed...\n",
            "user num  2 samp no 7 processed...\n",
            "user num  2 samp no 8 processed...\n",
            "user num  2 samp no 9 processed...\n",
            "user num  2 samp no 10 processed...\n",
            "user num  3 samp no 1 processed...\n",
            "user num  3 samp no 2 processed...\n",
            "user num  3 samp no 3 processed...\n",
            "user num  3 samp no 4 processed...\n",
            "user num  3 samp no 5 processed...\n",
            "user num  3 samp no 6 processed...\n",
            "user num  3 samp no 7 processed...\n",
            "user num  3 samp no 8 processed...\n",
            "user num  3 samp no 9 processed...\n",
            "user num  3 samp no 10 processed...\n",
            "user num  4 samp no 1 processed...\n",
            "user num  4 samp no 2 processed...\n",
            "user num  4 samp no 3 processed...\n",
            "user num  4 samp no 4 processed...\n",
            "user num  4 samp no 5 processed...\n",
            "user num  4 samp no 6 processed...\n",
            "user num  4 samp no 7 processed...\n",
            "user num  4 samp no 8 processed...\n",
            "user num  4 samp no 9 processed...\n",
            "user num  4 samp no 10 processed...\n",
            "user num  5 samp no 1 processed...\n",
            "user num  5 samp no 2 processed...\n",
            "user num  5 samp no 3 processed...\n",
            "user num  5 samp no 4 processed...\n",
            "user num  5 samp no 5 processed...\n",
            "user num  5 samp no 6 processed...\n",
            "user num  5 samp no 7 processed...\n",
            "user num  5 samp no 8 processed...\n",
            "user num  5 samp no 9 processed...\n",
            "user num  5 samp no 10 processed...\n",
            "user num  6 samp no 1 processed...\n",
            "user num  6 samp no 2 processed...\n",
            "user num  6 samp no 3 processed...\n",
            "user num  6 samp no 4 processed...\n",
            "user num  6 samp no 5 processed...\n",
            "user num  6 samp no 6 processed...\n",
            "user num  6 samp no 7 processed...\n",
            "user num  6 samp no 8 processed...\n",
            "user num  6 samp no 9 processed...\n",
            "user num  6 samp no 10 processed...\n",
            "user num  7 samp no 1 processed...\n",
            "user num  7 samp no 2 processed...\n",
            "user num  7 samp no 3 processed...\n",
            "user num  7 samp no 4 processed...\n",
            "user num  7 samp no 5 processed...\n",
            "user num  7 samp no 6 processed...\n",
            "user num  7 samp no 7 processed...\n",
            "user num  7 samp no 8 processed...\n",
            "user num  7 samp no 9 processed...\n",
            "user num  7 samp no 10 processed...\n",
            "user num  8 samp no 1 processed...\n",
            "user num  8 samp no 2 processed...\n",
            "user num  8 samp no 3 processed...\n",
            "user num  8 samp no 4 processed...\n",
            "user num  8 samp no 5 processed...\n",
            "user num  8 samp no 6 processed...\n",
            "user num  8 samp no 7 processed...\n",
            "user num  8 samp no 8 processed...\n",
            "user num  8 samp no 9 processed...\n",
            "user num  8 samp no 10 processed...\n",
            "user num  9 samp no 1 processed...\n",
            "user num  9 samp no 2 processed...\n",
            "user num  9 samp no 3 processed...\n",
            "user num  9 samp no 4 processed...\n",
            "user num  9 samp no 5 processed...\n",
            "user num  9 samp no 6 processed...\n",
            "user num  9 samp no 7 processed...\n",
            "user num  9 samp no 8 processed...\n",
            "user num  9 samp no 9 processed...\n",
            "user num  9 samp no 10 processed...\n",
            "user num  10 samp no 1 processed...\n",
            "user num  10 samp no 2 processed...\n",
            "user num  10 samp no 3 processed...\n",
            "user num  10 samp no 4 processed...\n",
            "user num  10 samp no 5 processed...\n",
            "user num  10 samp no 6 processed...\n",
            "user num  10 samp no 7 processed...\n",
            "user num  10 samp no 8 processed...\n",
            "user num  10 samp no 9 processed...\n",
            "user num  10 samp no 10 processed...\n",
            "user num  11 samp no 1 processed...\n",
            "user num  11 samp no 2 processed...\n",
            "user num  11 samp no 3 processed...\n",
            "user num  11 samp no 4 processed...\n",
            "user num  11 samp no 5 processed...\n",
            "user num  11 samp no 6 processed...\n",
            "user num  11 samp no 7 processed...\n",
            "user num  11 samp no 8 processed...\n",
            "user num  11 samp no 9 processed...\n",
            "user num  11 samp no 10 processed...\n",
            "user num  12 samp no 1 processed...\n",
            "user num  12 samp no 2 processed...\n",
            "user num  12 samp no 3 processed...\n",
            "user num  12 samp no 4 processed...\n",
            "user num  12 samp no 5 processed...\n",
            "user num  12 samp no 6 processed...\n",
            "user num  12 samp no 7 processed...\n",
            "user num  12 samp no 8 processed...\n",
            "user num  12 samp no 9 processed...\n",
            "user num  12 samp no 10 processed...\n",
            "user num  13 samp no 1 processed...\n",
            "user num  13 samp no 2 processed...\n",
            "user num  13 samp no 3 processed...\n",
            "user num  13 samp no 4 processed...\n",
            "user num  13 samp no 5 processed...\n",
            "user num  13 samp no 6 processed...\n",
            "user num  13 samp no 7 processed...\n",
            "user num  13 samp no 8 processed...\n",
            "user num  13 samp no 9 processed...\n",
            "user num  13 samp no 10 processed...\n",
            "user num  14 samp no 1 processed...\n",
            "user num  14 samp no 2 processed...\n",
            "user num  14 samp no 3 processed...\n",
            "user num  14 samp no 4 processed...\n",
            "user num  14 samp no 5 processed...\n",
            "user num  14 samp no 6 processed...\n",
            "user num  14 samp no 7 processed...\n",
            "user num  14 samp no 8 processed...\n",
            "user num  14 samp no 9 processed...\n",
            "user num  14 samp no 10 processed...\n",
            "user num  15 samp no 1 processed...\n",
            "user num  15 samp no 2 processed...\n",
            "user num  15 samp no 3 processed...\n",
            "user num  15 samp no 4 processed...\n",
            "user num  15 samp no 5 processed...\n",
            "user num  15 samp no 6 processed...\n",
            "user num  15 samp no 7 processed...\n",
            "user num  15 samp no 8 processed...\n",
            "user num  15 samp no 9 processed...\n",
            "user num  15 samp no 10 processed...\n",
            "user num  16 samp no 1 processed...\n",
            "user num  16 samp no 2 processed...\n",
            "user num  16 samp no 3 processed...\n",
            "user num  16 samp no 4 processed...\n",
            "user num  16 samp no 5 processed...\n",
            "user num  16 samp no 6 processed...\n",
            "user num  16 samp no 7 processed...\n",
            "user num  16 samp no 8 processed...\n",
            "user num  16 samp no 9 processed...\n",
            "user num  16 samp no 10 processed...\n",
            "user num  17 samp no 1 processed...\n",
            "user num  17 samp no 2 processed...\n",
            "user num  17 samp no 3 processed...\n",
            "user num  17 samp no 4 processed...\n",
            "user num  17 samp no 5 processed...\n",
            "user num  17 samp no 6 processed...\n",
            "user num  17 samp no 7 processed...\n",
            "user num  17 samp no 8 processed...\n",
            "user num  17 samp no 9 processed...\n",
            "user num  17 samp no 10 processed...\n",
            "user num  18 samp no 1 processed...\n",
            "user num  18 samp no 2 processed...\n",
            "user num  18 samp no 3 processed...\n",
            "user num  18 samp no 4 processed...\n",
            "user num  18 samp no 5 processed...\n",
            "user num  18 samp no 6 processed...\n",
            "user num  18 samp no 7 processed...\n",
            "user num  18 samp no 8 processed...\n",
            "user num  18 samp no 9 processed...\n",
            "user num  18 samp no 10 processed...\n",
            "user num  19 samp no 1 processed...\n",
            "user num  19 samp no 2 processed...\n",
            "user num  19 samp no 3 processed...\n",
            "user num  19 samp no 4 processed...\n",
            "user num  19 samp no 5 processed...\n",
            "user num  19 samp no 6 processed...\n",
            "user num  19 samp no 7 processed...\n",
            "user num  19 samp no 8 processed...\n",
            "user num  19 samp no 9 processed...\n",
            "user num  19 samp no 10 processed...\n",
            "user num  20 samp no 1 processed...\n",
            "user num  20 samp no 2 processed...\n",
            "user num  20 samp no 3 processed...\n",
            "user num  20 samp no 4 processed...\n",
            "user num  20 samp no 5 processed...\n",
            "user num  20 samp no 6 processed...\n",
            "user num  20 samp no 7 processed...\n",
            "user num  20 samp no 8 processed...\n",
            "user num  20 samp no 9 processed...\n",
            "user num  20 samp no 10 processed...\n",
            "user num  21 samp no 1 processed...\n",
            "user num  21 samp no 2 processed...\n",
            "user num  21 samp no 3 processed...\n",
            "user num  21 samp no 4 processed...\n",
            "user num  21 samp no 5 processed...\n",
            "user num  21 samp no 6 processed...\n",
            "user num  21 samp no 7 processed...\n",
            "user num  21 samp no 8 processed...\n",
            "user num  21 samp no 9 processed...\n",
            "user num  21 samp no 10 processed...\n",
            "user num  22 samp no 1 processed...\n",
            "user num  22 samp no 2 processed...\n",
            "user num  22 samp no 3 processed...\n",
            "user num  22 samp no 4 processed...\n",
            "user num  22 samp no 5 processed...\n",
            "user num  22 samp no 6 processed...\n",
            "user num  22 samp no 7 processed...\n",
            "user num  22 samp no 8 processed...\n",
            "user num  22 samp no 9 processed...\n",
            "user num  22 samp no 10 processed...\n",
            "user num  23 samp no 1 processed...\n",
            "user num  23 samp no 2 processed...\n",
            "user num  23 samp no 3 processed...\n",
            "user num  23 samp no 4 processed...\n",
            "user num  23 samp no 5 processed...\n",
            "user num  23 samp no 6 processed...\n",
            "user num  23 samp no 7 processed...\n",
            "user num  23 samp no 8 processed...\n",
            "user num  23 samp no 9 processed...\n",
            "user num  23 samp no 10 processed...\n",
            "user num  24 samp no 1 processed...\n",
            "user num  24 samp no 2 processed...\n",
            "user num  24 samp no 3 processed...\n",
            "user num  24 samp no 4 processed...\n",
            "user num  24 samp no 5 processed...\n",
            "user num  24 samp no 6 processed...\n",
            "user num  24 samp no 7 processed...\n",
            "user num  24 samp no 8 processed...\n",
            "user num  24 samp no 9 processed...\n",
            "user num  24 samp no 10 processed...\n",
            "user num  25 samp no 1 processed...\n",
            "user num  25 samp no 2 processed...\n",
            "user num  25 samp no 3 processed...\n",
            "user num  25 samp no 4 processed...\n",
            "user num  25 samp no 5 processed...\n",
            "user num  25 samp no 6 processed...\n",
            "user num  25 samp no 7 processed...\n",
            "user num  25 samp no 8 processed...\n",
            "user num  25 samp no 9 processed...\n",
            "user num  25 samp no 10 processed...\n",
            "user num  26 samp no 1 processed...\n",
            "user num  26 samp no 2 processed...\n",
            "user num  26 samp no 3 processed...\n",
            "user num  26 samp no 4 processed...\n",
            "user num  26 samp no 5 processed...\n",
            "user num  26 samp no 6 processed...\n",
            "user num  26 samp no 7 processed...\n",
            "user num  26 samp no 8 processed...\n",
            "user num  26 samp no 9 processed...\n",
            "user num  26 samp no 10 processed...\n",
            "user num  27 samp no 1 processed...\n",
            "user num  27 samp no 2 processed...\n",
            "user num  27 samp no 3 processed...\n",
            "user num  27 samp no 4 processed...\n",
            "user num  27 samp no 5 processed...\n",
            "user num  27 samp no 6 processed...\n",
            "user num  27 samp no 7 processed...\n",
            "user num  27 samp no 8 processed...\n",
            "user num  27 samp no 9 processed...\n",
            "user num  27 samp no 10 processed...\n",
            "user num  28 samp no 1 processed...\n",
            "user num  28 samp no 2 processed...\n",
            "user num  28 samp no 3 processed...\n",
            "user num  28 samp no 4 processed...\n",
            "user num  28 samp no 5 processed...\n",
            "user num  28 samp no 6 processed...\n",
            "user num  28 samp no 7 processed...\n",
            "user num  28 samp no 8 processed...\n",
            "user num  28 samp no 9 processed...\n",
            "user num  28 samp no 10 processed...\n",
            "user num  29 samp no 1 processed...\n",
            "user num  29 samp no 2 processed...\n",
            "user num  29 samp no 3 processed...\n",
            "user num  29 samp no 4 processed...\n",
            "user num  29 samp no 5 processed...\n",
            "user num  29 samp no 6 processed...\n",
            "user num  29 samp no 7 processed...\n",
            "user num  29 samp no 8 processed...\n",
            "user num  29 samp no 9 processed...\n",
            "user num  29 samp no 10 processed...\n",
            "user num  30 samp no 1 processed...\n",
            "user num  30 samp no 2 processed...\n",
            "user num  30 samp no 3 processed...\n",
            "user num  30 samp no 4 processed...\n",
            "user num  30 samp no 5 processed...\n",
            "user num  30 samp no 6 processed...\n",
            "user num  30 samp no 7 processed...\n",
            "user num  30 samp no 8 processed...\n",
            "user num  30 samp no 9 processed...\n",
            "user num  30 samp no 10 processed...\n",
            "user num  31 samp no 1 processed...\n",
            "user num  31 samp no 2 processed...\n",
            "user num  31 samp no 3 processed...\n",
            "user num  31 samp no 4 processed...\n",
            "user num  31 samp no 5 processed...\n",
            "user num  31 samp no 6 processed...\n",
            "user num  31 samp no 7 processed...\n",
            "user num  31 samp no 8 processed...\n",
            "user num  31 samp no 9 processed...\n",
            "user num  31 samp no 10 processed...\n",
            "user num  32 samp no 1 processed...\n",
            "user num  32 samp no 2 processed...\n",
            "user num  32 samp no 3 processed...\n",
            "user num  32 samp no 4 processed...\n",
            "user num  32 samp no 5 processed...\n",
            "user num  32 samp no 6 processed...\n",
            "user num  32 samp no 7 processed...\n",
            "user num  32 samp no 8 processed...\n",
            "user num  32 samp no 9 processed...\n",
            "user num  32 samp no 10 processed...\n",
            "user num  33 samp no 1 processed...\n",
            "user num  33 samp no 2 processed...\n",
            "user num  33 samp no 3 processed...\n",
            "user num  33 samp no 4 processed...\n",
            "user num  33 samp no 5 processed...\n",
            "user num  33 samp no 6 processed...\n",
            "user num  33 samp no 7 processed...\n",
            "user num  33 samp no 8 processed...\n",
            "user num  33 samp no 9 processed...\n",
            "user num  33 samp no 10 processed...\n",
            "user num  34 samp no 1 processed...\n",
            "user num  34 samp no 2 processed...\n",
            "user num  34 samp no 3 processed...\n",
            "user num  34 samp no 4 processed...\n",
            "user num  34 samp no 5 processed...\n",
            "user num  34 samp no 6 processed...\n",
            "user num  34 samp no 7 processed...\n",
            "user num  34 samp no 8 processed...\n",
            "user num  34 samp no 9 processed...\n",
            "user num  34 samp no 10 processed...\n",
            "user num  35 samp no 1 processed...\n",
            "user num  35 samp no 2 processed...\n",
            "user num  35 samp no 3 processed...\n",
            "user num  35 samp no 4 processed...\n",
            "user num  35 samp no 5 processed...\n",
            "user num  35 samp no 6 processed...\n",
            "user num  35 samp no 7 processed...\n",
            "user num  35 samp no 8 processed...\n",
            "user num  35 samp no 9 processed...\n",
            "user num  35 samp no 10 processed...\n",
            "user num  36 samp no 1 processed...\n",
            "user num  36 samp no 2 processed...\n",
            "user num  36 samp no 3 processed...\n",
            "user num  36 samp no 4 processed...\n",
            "user num  36 samp no 5 processed...\n",
            "user num  36 samp no 6 processed...\n",
            "user num  36 samp no 7 processed...\n",
            "user num  36 samp no 8 processed...\n",
            "user num  36 samp no 9 processed...\n",
            "user num  36 samp no 10 processed...\n",
            "user num  37 samp no 1 processed...\n",
            "user num  37 samp no 2 processed...\n",
            "user num  37 samp no 3 processed...\n",
            "user num  37 samp no 4 processed...\n",
            "user num  37 samp no 5 processed...\n",
            "user num  37 samp no 6 processed...\n",
            "user num  37 samp no 7 processed...\n",
            "user num  37 samp no 8 processed...\n",
            "user num  37 samp no 9 processed...\n",
            "user num  37 samp no 10 processed...\n",
            "user num  38 samp no 1 processed...\n",
            "user num  38 samp no 2 processed...\n",
            "user num  38 samp no 3 processed...\n",
            "user num  38 samp no 4 processed...\n",
            "user num  38 samp no 5 processed...\n",
            "user num  38 samp no 6 processed...\n",
            "user num  38 samp no 7 processed...\n",
            "user num  38 samp no 8 processed...\n",
            "user num  38 samp no 9 processed...\n",
            "user num  38 samp no 10 processed...\n",
            "user num  39 samp no 1 processed...\n",
            "user num  39 samp no 2 processed...\n",
            "user num  39 samp no 3 processed...\n",
            "user num  39 samp no 4 processed...\n",
            "user num  39 samp no 5 processed...\n",
            "user num  39 samp no 6 processed...\n",
            "user num  39 samp no 7 processed...\n",
            "user num  39 samp no 8 processed...\n",
            "user num  39 samp no 9 processed...\n",
            "user num  39 samp no 10 processed...\n",
            "user num  40 samp no 1 processed...\n",
            "user num  40 samp no 2 processed...\n",
            "user num  40 samp no 3 processed...\n",
            "user num  40 samp no 4 processed...\n",
            "user num  40 samp no 5 processed...\n",
            "user num  40 samp no 6 processed...\n",
            "user num  40 samp no 7 processed...\n",
            "user num  40 samp no 8 processed...\n",
            "user num  40 samp no 9 processed...\n",
            "user num  40 samp no 10 processed...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.copy()\n",
        "y = label.copy()\n",
        "\n",
        "\n",
        "# split the data into 70:30 ratio\n",
        "Xtrain,Xtest,Ytrain,ytest = model_selection.train_test_split(X,y,test_size=0.3,random_state=5)\n",
        "print(Xtrain.shape,Ytrain.shape)\n",
        "print(Xtest.shape,ytest.shape)\n",
        "\n",
        "ker = ['poly','linear','rbf']\n",
        "c_value = [1,2,3]\n",
        "\n",
        "# pre allocation of the result variable\n",
        "result = np.zeros((len(ker),len(c_value)))\n",
        "for i in range(len(ker)):\n",
        "  for j in range(len(c_value)):\n",
        "    # create the svm classifier\n",
        "    orl_svm_model = svm.SVC(kernel=ker[i],gamma='scale',C=c_value[j])\n",
        "\n",
        "    # train the model\n",
        "    orl_svm_model = orl_svm_model.fit(Xtrain,Ytrain)\n",
        "\n",
        "    # predict the labels\n",
        "    ypred = orl_svm_model.predict(Xtest)\n",
        "\n",
        "    # accuracy\n",
        "    acc = metrics.accuracy_score(ypred,ytest)\n",
        "    #print(\"accuracy:\", acc)\n",
        "    result[i,j]=acc\n",
        "print(result)\n",
        "\n",
        "ResultDF = pd.DataFrame(result,index=ker,columns=[\"C=1\",\"C=2\",\"C=3\"])\n",
        "print(ResultDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kspxT9CikN6J",
        "outputId": "7030c362-9f93-4fe8-f3e2-1e8eb5981dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(280, 10304) (280,)\n",
            "(120, 10304) (120,)\n",
            "[[0.94166667 0.94166667 0.94166667]\n",
            " [0.95       0.95       0.95      ]\n",
            " [0.88333333 0.95       0.95      ]]\n",
            "             C=1       C=2       C=3\n",
            "poly    0.941667  0.941667  0.941667\n",
            "linear  0.950000  0.950000  0.950000\n",
            "rbf     0.883333  0.950000  0.950000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with CNN Model"
      ],
      "metadata": {
        "id": "_z5X86_rk-U6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create the CNN model\n",
        "cnn_model = keras.models.Sequential() # empty framework\n",
        "# Convolutinal layer 1\n",
        "cnn_model.add(keras.layers.Conv1D(20,3,activation='relu',input_shape=(10304,1)))\n",
        "# maxpooling -1\n",
        "cnn_model.add(keras.layers.MaxPool1D(2))\n",
        "\n",
        "# Convolutinal layer 2\n",
        "cnn_model.add(keras.layers.Conv1D(40,3,activation='relu'))\n",
        "# maxpooling -2\n",
        "cnn_model.add(keras.layers.MaxPool1D(2))\n",
        "\n",
        "# feed forwards network\n",
        "cnn_model.add(keras.layers.Flatten()) # input layer\n",
        "cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL1\n",
        "cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL2\n",
        "cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL3\n",
        "cnn_model.add(keras.layers.Dense(len(np.unique(Ytrain))+1)) # Output layer\n",
        "\n",
        "# optimizer\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "cnn_model.compile(optimizer='sgd',loss = loss,metrics=['accuracy'])\n",
        "cnn_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJt9UG1elEAL",
        "outputId": "64141345-139d-49d8-a47f-e50717c23a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 10302, 20)         80        \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 5151, 20)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 5149, 40)          2440      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 2574, 40)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 102960)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               20592200  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 41)                8241      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20683361 (78.90 MB)\n",
            "Trainable params: 20683361 (78.90 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the cnn along with the validation data\n",
        "history = cnn_model.fit(Xtrain,Ytrain,epochs=100,validation_data=(Xtest,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygIUlCO4lbzS",
        "outputId": "2a2d0b92-9db1-4566-dcd1-6cce9e6942e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "9/9 [==============================] - 8s 784ms/step - loss: 3.7129 - accuracy: 0.0286 - val_loss: 3.7098 - val_accuracy: 0.0250\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 4s 488ms/step - loss: 3.6975 - accuracy: 0.0250 - val_loss: 3.6998 - val_accuracy: 0.0417\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 4s 491ms/step - loss: 3.6821 - accuracy: 0.0536 - val_loss: 3.7087 - val_accuracy: 0.0417\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 6s 737ms/step - loss: 3.6707 - accuracy: 0.0750 - val_loss: 3.6933 - val_accuracy: 0.0250\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 4s 486ms/step - loss: 3.6564 - accuracy: 0.0821 - val_loss: 3.6841 - val_accuracy: 0.0333\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 4s 486ms/step - loss: 3.6381 - accuracy: 0.0607 - val_loss: 3.6688 - val_accuracy: 0.0750\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 6s 718ms/step - loss: 3.6145 - accuracy: 0.1143 - val_loss: 3.6584 - val_accuracy: 0.0333\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 4s 484ms/step - loss: 3.5869 - accuracy: 0.0929 - val_loss: 3.6426 - val_accuracy: 0.0667\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 4s 495ms/step - loss: 3.5629 - accuracy: 0.1036 - val_loss: 3.6194 - val_accuracy: 0.0417\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 6s 746ms/step - loss: 3.5265 - accuracy: 0.1000 - val_loss: 3.6006 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 4s 470ms/step - loss: 3.4769 - accuracy: 0.1643 - val_loss: 3.5714 - val_accuracy: 0.0833\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 4s 493ms/step - loss: 3.4271 - accuracy: 0.1429 - val_loss: 3.5042 - val_accuracy: 0.0917\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 6s 748ms/step - loss: 3.3649 - accuracy: 0.1536 - val_loss: 3.4862 - val_accuracy: 0.0917\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 4s 496ms/step - loss: 3.2734 - accuracy: 0.1679 - val_loss: 3.4062 - val_accuracy: 0.0833\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 4s 494ms/step - loss: 3.2089 - accuracy: 0.1714 - val_loss: 3.3481 - val_accuracy: 0.0833\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 7s 780ms/step - loss: 3.0872 - accuracy: 0.1857 - val_loss: 3.2081 - val_accuracy: 0.1917\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 4s 498ms/step - loss: 2.9015 - accuracy: 0.2929 - val_loss: 3.2023 - val_accuracy: 0.0667\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 4s 493ms/step - loss: 2.7604 - accuracy: 0.2607 - val_loss: 3.0908 - val_accuracy: 0.1583\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 6s 753ms/step - loss: 2.5827 - accuracy: 0.3464 - val_loss: 2.8890 - val_accuracy: 0.2583\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 4s 469ms/step - loss: 2.4550 - accuracy: 0.3357 - val_loss: 2.8093 - val_accuracy: 0.3083\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 4s 496ms/step - loss: 2.3336 - accuracy: 0.3536 - val_loss: 2.6298 - val_accuracy: 0.2750\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 7s 755ms/step - loss: 2.1438 - accuracy: 0.4000 - val_loss: 2.4909 - val_accuracy: 0.3667\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 4s 482ms/step - loss: 1.8274 - accuracy: 0.5036 - val_loss: 2.0957 - val_accuracy: 0.3667\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 4s 464ms/step - loss: 1.8131 - accuracy: 0.4536 - val_loss: 2.5050 - val_accuracy: 0.2500\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 7s 782ms/step - loss: 1.5746 - accuracy: 0.5464 - val_loss: 1.7180 - val_accuracy: 0.4917\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 4s 489ms/step - loss: 1.2133 - accuracy: 0.6607 - val_loss: 2.1693 - val_accuracy: 0.3833\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 4s 484ms/step - loss: 1.3480 - accuracy: 0.6000 - val_loss: 2.7754 - val_accuracy: 0.2583\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 7s 764ms/step - loss: 1.4156 - accuracy: 0.6036 - val_loss: 1.3438 - val_accuracy: 0.6417\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 4s 493ms/step - loss: 0.6778 - accuracy: 0.8143 - val_loss: 1.1478 - val_accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 4s 450ms/step - loss: 0.6178 - accuracy: 0.8286 - val_loss: 2.9547 - val_accuracy: 0.2667\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 6s 758ms/step - loss: 1.2354 - accuracy: 0.7036 - val_loss: 0.9387 - val_accuracy: 0.7833\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 4s 471ms/step - loss: 0.3323 - accuracy: 0.9500 - val_loss: 1.1773 - val_accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 4s 475ms/step - loss: 0.6457 - accuracy: 0.8179 - val_loss: 1.5565 - val_accuracy: 0.5917\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 7s 760ms/step - loss: 0.4830 - accuracy: 0.8857 - val_loss: 0.6840 - val_accuracy: 0.8333\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 6s 650ms/step - loss: 0.2666 - accuracy: 0.9536 - val_loss: 0.7937 - val_accuracy: 0.8083\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 10s 1s/step - loss: 0.1743 - accuracy: 0.9679 - val_loss: 0.7688 - val_accuracy: 0.7917\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 5s 578ms/step - loss: 0.2620 - accuracy: 0.9393 - val_loss: 0.6875 - val_accuracy: 0.8250\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 4s 492ms/step - loss: 0.2114 - accuracy: 0.9536 - val_loss: 0.5949 - val_accuracy: 0.8750\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 5s 568ms/step - loss: 0.1144 - accuracy: 0.9893 - val_loss: 0.6047 - val_accuracy: 0.8417\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 5s 535ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.8583\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 4s 471ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.8750\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 5s 602ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.8750\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 6s 610ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.9083\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 4s 470ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.8750\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 5s 615ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.8750\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 5s 564ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.8750\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 4s 465ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.8833\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 5s 625ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9083\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 5s 604ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.8750\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 4s 475ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.8750\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 6s 645ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9083\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 5s 571ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9000\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 4s 460ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9083\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 6s 647ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.8917\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 5s 556ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9000\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 4s 454ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.8917\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 6s 679ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9000\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 5s 514ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9000\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 4s 502ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9083\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 5s 616ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.8917\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 5s 532ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.9000\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 4s 492ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9083\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 6s 707ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9000\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 4s 481ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9000\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 4s 504ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9000\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 6s 678ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9083\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 4s 455ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9083\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 4s 483ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9083\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 6s 745ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9000\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 5s 506ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.9083\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 4s 501ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9000\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 6s 726ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9083\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 4s 465ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.9167\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 4s 502ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.9167\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 7s 790ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9083\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 4s 489ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9167\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 4s 454ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.9083\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 6s 752ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9167\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 4s 497ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.9083\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 4s 458ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9167\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 7s 781ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9167\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 4s 503ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9083\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 4s 453ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.9167\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 7s 799ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.9167\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 4s 472ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.9083\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 4s 491ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9167\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 6s 754ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9167\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 4s 447ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9083\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 4s 480ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.9167\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 7s 766ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9250\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 4s 464ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.9250\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 4s 504ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9167\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 7s 774ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9167\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 4s 474ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9167\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 4s 482ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9167\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 7s 816ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9167\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 5s 512ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.9167\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 4s 495ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9167\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 6s 725ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9167\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 4s 490ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CXLVzWHCnCCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with NN"
      ],
      "metadata": {
        "id": "wXPQ9se-tItp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the neural network\n",
        "nn_model = keras.Sequential() # create an empty nn feed forward\n",
        "# framework\n",
        "nn_model.add(keras.layers.Flatten\n",
        " (input_shape=(Xtrain.shape[0],Xtrain.shape[1]))) # input layer\n",
        "\n",
        "nn_model.add(keras.layers.Dense(128,activation='relu')) # Hidden layer 1\n",
        "nn_model.add(keras.layers.Dense(256,activation='relu')) # Hidden layer 2\n",
        "nn_model.add(keras.layers.Dense(256,activation='relu')) # Hidden layer 3\n",
        "\n",
        "nn_model.add(keras.layers.Dense(len(np.unique(Ytrain)))) # output layer\n",
        "\n",
        "\n",
        "\n",
        "# optimizer add\n",
        "nn_model.compile(optimizer=\"SGD\",\n",
        "                 loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "print(nn_model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK5xpXEOtPC5",
        "outputId": "c60ffa65-e9be-4358-9819-aa49aafd6192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 2885120)           0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               369295488 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 40)                10280     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 369404584 (1.38 GB)\n",
            "Trainable params: 369404584 (1.38 GB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model for Xtrain and Ytrain\n",
        "history = nn_model.fit(Xtrain,Ytrain,epochs=20,validation_data=(Xtest,ytest))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "YIfWpZiYtYHc",
        "outputId": "d95ac4e3-fd22-489e-ad02-95626d5372b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 280, 10304), found shape=(None, 10304)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f28afb8b771f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model for Xtrain and Ytrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 280, 10304), found shape=(None, 10304)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.plot"
      ],
      "metadata": {
        "id": "gaoR15A5tZkN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}